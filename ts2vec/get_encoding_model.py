'''
Purpose:
    Train the ts2vec model using RNA sequences from the training and test sets, and save the model parameters.
    The trained model will be saved in the model_file file, and then used in LTP for encoding and completing downstream training and prediction.
Note:
    When packaging the training set, include the feature vectors.
    When packaging the test set, use the ts2vec module but do not package the feature vectors.
    The required file format in the specified folder is either bpseq or ct format.
    The code generates sequence encoding, label matrices, and feature encodings generated by ts2vec for the specified folder.
Hyperparameters:
    Sequence length range for trimming.
    Encoding method.
    How to use: Specify the maximum sequence length, RNA family name, and other parameters.
Important:
    The ts2vec model needs to be trained using both the training set and the test set (using only sequence information, not label information).
    When training the downstream model, it is necessary to differentiate between the training set and the test set. Therefore, read the training folder and test folder sequentially to facilitate subsequent differentiation.
'''

import os
import torch
import numpy as np
import sys
sys.path.insert(0, '../util')
from ts2vec import TS2Vec
from utils import get_ct_table, get_data, get_bpseq_table, get_args_from_json, set_random_seed


def encoding_model(dst, limit_length, file_type, name, device, repr_dim, cut_min_len, cut_max_len, epochs):
    

    train_test_file = os.listdir(os.path.join(dst, name))
    family = []
    for i in range(len(train_test_file)):
        family.append(train_test_file[i])

    train_len, test_len = 0, 0, 
    seq_list = [] 

    for i in range(len(family)):

        path = os.path.join(dst, name, family[i])

        if(file_type == 'bpseq'):
            seq_list_, _, _, _ = get_bpseq_table(path, limit_length)
        elif(file_type == 'ct'):
            seq_list_, _, _, _ = get_ct_table(path, limit_length)
        seq_list.extend(seq_list_)

        if(i == 0):
            train_len = len(seq_list)
        if(i == 1):
            test_len = len(seq_list) - train_len

    seq_list = get_data(np.array(seq_list))

    print('now fitting')
    print(train_len, test_len)

    # Train a TS2Vec model
    model = TS2Vec(
        input_dims=seq_list.shape[-1],
        device=device,
        output_dims=repr_dim
    )

    loss_log = model.fit(
        seq_list,
        min_len=cut_min_len, 
        max_len=cut_max_len, 
        n_epochs=epochs, 
        verbose=True
    )

    model.save('model_file/{}.pth'.format(name))
    print('model save success!')

def main():

    # get args from json file
    # args = get_args_from_json('../util/args_Arc128.json')
    args = get_args_from_json('../util/args_Arc512.json')

    # torch.manual_seed(args.seed)
    set_random_seed(args.seed)
    
    limit_length = args.max_seq_len
    file_type = args.file_type
    encoding_model_name = args.encoding_model_name
    repr_dim = args.repr_dim
    cut_min_len = args.cut_min_len
    cut_max_len = args.cut_max_len
    epochs = args.encoding_model_epochs
    device = args.device

    name = encoding_model_name + '-{}'.format(limit_length)
    dst = 'datasets'

    encoding_model(dst, limit_length, file_type, name, device, repr_dim, cut_min_len, cut_max_len, epochs)


if __name__ == '__main__':
    
    main()